{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import queue\n",
    "from collections import deque\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming problem and the next you'll code up the greedy algorithm from the lectures on Huffman coding.\n",
    "\n",
    "Download the text file below.\n",
    "\n",
    "This file describes an instance of the problem. It has the following format:\n",
    "\n",
    "[number_of_symbols]\n",
    "\n",
    "[weight of symbol #1]\n",
    "\n",
    "[weight of symbol #2]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file is \"6852892,\" indicating that the weight of the second symbol of the alphabet is 6852892. (We're using weights instead of frequencies, like in the \"A More Complex Example\" video.)\n",
    "\n",
    "Your task in this problem is to run the Huffman coding algorithm from lecture on this data set. What is the maximum length of a codeword in the resulting Huffman code?\n",
    "\n",
    "ADVICE: If you're not getting the correct answer, try debugging your algorithm using some small test cases. And then post them to the discussion forum!\n",
    "\n",
    "Continuing the previous problem, what is the minimum length of a codeword in your Huffman code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HuffmanNode(object):\n",
    "    def __init__(self,left=None,right=None,root=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.root = root\n",
    "    def children(self):\n",
    "        return (self.left,self.right)\n",
    "    \n",
    "    #preorder traversal to generate the huffman encoding\n",
    "    def preorder(self,path=None,G=None):\n",
    "        if path is None:\n",
    "            path = ''\n",
    "        if G is None:\n",
    "            G = {}\n",
    "        if self.left is not None:\n",
    "            if isinstance(self.left[1],HuffmanNode):\n",
    "                self.left[1].preorder(path+'0',G)\n",
    "            else:\n",
    "                G[self.left[1]] = path+'0'\n",
    "                \n",
    "        if self.right is not None:\n",
    "            if isinstance(self.right[1],HuffmanNode):\n",
    "                self.right[1].preorder(path+'1',G)\n",
    "            else:\n",
    "                G[self.right[1]] = path+'1'\n",
    "    \n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def huffman_code_heap(filename):\n",
    "    first = True\n",
    "    symbol = 0\n",
    "    p = queue.PriorityQueue()\n",
    "    with open('week11_file/'+filename) as f:\n",
    "        for line in f:\n",
    "            line = line.split() # to deal with blank \n",
    "            if line and not first:            # lines (ie skip them)\n",
    "                weight = int(line[0])\n",
    "                #add all the symbols to the heap, key = frequencies\n",
    "                p.put([weight,symbol])\n",
    "                symbol+=1\n",
    "            else:\n",
    "                num_symbols = int(line[0])\n",
    "                first = False\n",
    "    \n",
    "    #while there are two or more nodes in the heap\n",
    "    while p.qsize()>1:\n",
    "        #extract the two smallest-frequency symbols\n",
    "        left, right = p.get(),p.get()\n",
    "        node = HuffmanNode(left,right)\n",
    "        #re-insert the new meta-symbol (new key = sum of two old ones)\n",
    "        p.put([left[0]+right[0],node])\n",
    "    \n",
    "    node = p.get()\n",
    "    G = node[1].preorder()\n",
    "    sorted_length = sorted(G.values(),key=len)\n",
    "    min_length = len(sorted_length[0])\n",
    "    max_length = len(sorted_length[-1])\n",
    "    return min_length,max_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "--- 0.0035440921783447266 seconds ---\n",
      "(3, 6)\n",
      "--- 0.001893758773803711 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(huffman_code_heap('week11_1_test1.txt')) #2,5\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "print(huffman_code_heap('week11_1_test2.txt')) #3,6\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 19)\n",
      "--- 0.03994107246398926 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(huffman_code_heap('week11_1.txt')) #9,19\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def huffman_code_queue(filename):\n",
    "    first = True\n",
    "    symbol = 0\n",
    "    q_first = deque()\n",
    "    q_second = deque()\n",
    "    graph = []\n",
    "    with open('week11_file/'+filename) as f:\n",
    "        for line in f:\n",
    "            line = line.split() # to deal with blank \n",
    "            if line and not first:            # lines (ie skip them)\n",
    "                weight = int(line[0])\n",
    "                graph.append([weight,symbol])\n",
    "                symbol+=1\n",
    "            else:\n",
    "                num_symbols = int(line[0])\n",
    "                first = False\n",
    "                \n",
    "    graph = sorted(graph,key=lambda x:x[0])\n",
    "   \n",
    "    #enqueue all leaf nodes into the first queue in increasing order of frequencies\n",
    "    for i in range(len(graph)):\n",
    "        q_first.append(graph[i])\n",
    "    \n",
    "    #while there are two or more nodes in both of the queues, dequeue the two nodes with lowest weight by examining\n",
    "    #the fronts of both queues\n",
    "    while len(q_first)+len(q_second) >1:\n",
    "        min_node = [0]*2\n",
    "        for i in range(2):\n",
    "            if len(q_second) == 0:\n",
    "                min_node[i] = q_first.popleft()\n",
    "            elif len(q_first) == 0:\n",
    "                min_node[i] = q_second.popleft()\n",
    "            else:\n",
    "                if q_first[0] < q_second[0]:\n",
    "                    min_node[i] = q_first.popleft()\n",
    "                else:\n",
    "                    min_node[i] = q_second.popleft()\n",
    "        left = min_node[0]\n",
    "        right = min_node[1]\n",
    "        node = HuffmanNode(left,right)\n",
    "        #engueue the new node into the second queue (key = sum of the two old frequencies)\n",
    "        q_second.append([left[0]+right[0],node])\n",
    "    \n",
    "    if len(q_first) == 1:\n",
    "        node = q_first[0]\n",
    "    else:\n",
    "        node = q_second[0]\n",
    "        \n",
    "    G = node[1].preorder()\n",
    "    sorted_length = sorted(G.values(),key=len)\n",
    "    min_length = len(sorted_length[0])\n",
    "    max_length = len(sorted_length[-1])\n",
    "    return min_length,max_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "--- 0.0015480518341064453 seconds ---\n",
      "(3, 6)\n",
      "--- 0.000621795654296875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(huffman_code_queue('week11_1_test1.txt')) #2,5\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "print(huffman_code_queue('week11_1_test2.txt')) #3,6\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 19)\n",
      "--- 0.03961801528930664 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(huffman_code_queue('week11_1.txt')) #9,19\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming problem you'll code up the dynamic programming algorithm for computing a maximum-weight independent set of a path graph.\n",
    "\n",
    "Download the text file below.\n",
    "\n",
    "This file describes the weights of the vertices in a path graph (with the weights listed in the order in which vertices appear in the path). It has the following format:\n",
    "\n",
    "[number_of_vertices]\n",
    "\n",
    "[weight of first vertex]\n",
    "\n",
    "[weight of second vertex]\n",
    "\n",
    "...\n",
    "\n",
    "For example, the third line of the file is \"6395702,\" indicating that the weight of the second vertex of the graph is 6395702.\n",
    "\n",
    "Your task in this problem is to run the dynamic programming algorithm (and the reconstruction procedure) from lecture on this data set. The question is: of the vertices 1, 2, 3, 4, 17, 117, 517, and 997, which ones belong to the maximum-weight independent set? (By \"vertex 1\" we mean the first vertex of the graph---there is no vertex 0.) In the box below, enter a 8-bit string, where the ith bit should be 1 if the ith of these 8 vertices is in the maximum-weight independent set, and 0 otherwise. For example, if you think that the vertices 1, 4, 17, and 517 are in the maximum-weight independent set and the other four vertices are not, then you should enter the string 10011010 in the box below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_independent_set(filename):\n",
    "    first = True\n",
    "    counter= 0\n",
    "    with open('week11_file/'+filename) as f:\n",
    "        for line in f:\n",
    "            line = line.split() # to deal with blank \n",
    "            if line and not first:            # lines (ie skip them)\n",
    "                weight = int(line[0])\n",
    "                G[counter] = weight\n",
    "                counter+=1\n",
    "            else:\n",
    "                num_vertices = int(line[0])\n",
    "                G = [0]*num_vertices\n",
    "                first = False\n",
    "    A = [0,G[0]]\n",
    "    for i in range(2,len(G)+1):\n",
    "        #two cases: 1) Max-wt IS of Gi-1 and 2) max-wt IS of Gi-2 + {vn}\n",
    "        optim_value = max(A[i-1],A[i-2]+G[i-1]) #A[i] is the maximum weight IS of Gi (G is 1 based indexing)\n",
    "        A.append(optim_value)\n",
    "    \n",
    "    S = deque()\n",
    "    i = len(A)-1\n",
    "    \n",
    "    #Reconstruction Algorithm\n",
    "    \n",
    "    #Scan through array from right to left\n",
    "    while i>=1:\n",
    "        #Case 1 wins\n",
    "        if A[i-1] >= A[i-2] + G[i-1]:\n",
    "            i-=1\n",
    "        else:\n",
    "            #Case 2 wins\n",
    "            S.appendleft(i)\n",
    "            i-=2\n",
    "    \n",
    "    return A[-1],S\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2616, deque([2, 4, 6, 8, 10]))\n",
      "--- 0.002702951431274414 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(weighted_independent_set('week11_2_test1.txt')) #Max sum: 2616, Chosen points (position): [2, 4, 6, 8, 10]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2533, deque([1, 3, 6, 9]))\n",
      "--- 0.010534048080444336 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(weighted_independent_set('week11_2_test2.txt')) #Max sum: 2533,Chosen points (position): [1, 3, 6, 9]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2955353732, deque([1, 3, 5, 8, 10, 13, 15, 18, 20, 22, 24, 26, 28, 31, 33, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 69, 72, 75, 77, 79, 81, 83, 85, 88, 90, 92, 94, 96, 98, 100, 103, 106, 108, 110, 112, 115, 117, 120, 122, 124, 126, 128, 131, 133, 136, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 160, 162, 164, 166, 168, 170, 173, 175, 177, 179, 181, 183, 185, 187, 190, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 214, 216, 218, 221, 223, 226, 228, 230, 232, 234, 236, 238, 240, 243, 245, 247, 249, 252, 254, 256, 258, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343, 345, 347, 349, 351, 353, 355, 357, 359, 361, 363, 365, 367, 369, 371, 373, 375, 377, 379, 381, 383, 385, 387, 389, 391, 393, 395, 397, 399, 402, 404, 406, 408, 410, 413, 415, 417, 420, 422, 425, 427, 429, 431, 433, 435, 437, 439, 441, 443, 445, 447, 449, 451, 454, 456, 458, 460, 462, 464, 466, 468, 470, 472, 474, 476, 478, 481, 483, 485, 488, 490, 492, 494, 496, 498, 500, 503, 505, 508, 510, 512, 514, 517, 519, 521, 523, 525, 527, 529, 531, 534, 537, 539, 541, 543, 545, 548, 550, 552, 554, 556, 558, 560, 563, 566, 569, 571, 573, 575, 577, 579, 581, 584, 586, 588, 590, 592, 594, 596, 598, 600, 602, 604, 606, 608, 610, 613, 615, 617, 619, 621, 623, 625, 628, 630, 632, 634, 637, 639, 641, 643, 645, 647, 649, 652, 654, 656, 658, 660, 662, 664, 666, 669, 671, 673, 676, 679, 682, 684, 686, 688, 690, 692, 695, 697, 699, 702, 704, 706, 708, 710, 713, 715, 717, 719, 721, 723, 726, 728, 730, 733, 735, 737, 739, 741, 743, 745, 748, 750, 752, 755, 757, 760, 763, 766, 768, 770, 772, 774, 776, 778, 781, 784, 786, 788, 790, 793, 795, 797, 799, 801, 803, 806, 809, 812, 814, 816, 819, 821, 823, 825, 827, 829, 832, 834, 837, 839, 841, 843, 846, 849, 851, 853, 855, 857, 859, 861, 864, 866, 868, 871, 873, 876, 878, 880, 882, 884, 886, 888, 890, 892, 894, 896, 898, 900, 903, 905, 907, 909, 911, 913, 915, 917, 919, 921, 924, 927, 929, 932, 934, 936, 938, 940, 942, 944, 946, 948, 950, 952, 954, 956, 958, 960, 962, 964, 966, 969, 971, 973, 975, 977, 979, 981, 983, 985, 987, 989, 991, 993, 995, 998, 1000]))\n",
      "--- 0.0051577091217041016 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(weighted_independent_set('week11_2.txt')) #Max sum: 2955353732,Chosen points (position): 10100110\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
